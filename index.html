<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Client-Side WSI Pipeline (Multi-Task)</title>
    
    <!-- 1. Import Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.16.3/dist/ort.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/geotiff@2.1.0/dist-browser/geotiff.js"></script>
    
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; max-width: 1200px; margin: 0 auto; padding: 20px; background: #f0f2f5; color: #333; }
        h1 { color: #1a1a1a; margin-bottom: 0.5rem; }
        p.subtitle { color: #666; margin-bottom: 2rem; }

        /* Error Banner */
        #global-error { display: none; background: #ffebee; color: #c62828; padding: 15px; border-radius: 8px; margin-bottom: 20px; border: 1px solid #ef9a9a; font-weight: bold; }

        .grid-container { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
        
        /* Cards */
        .card { background: white; padding: 20px; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); display: flex; flex-direction: column; }
        h3 { margin-top: 0; border-bottom: 2px solid #f0f0f0; padding-bottom: 10px; font-size: 1.1rem; }

        /* Upload Boxes */
        .upload-box { border: 2px dashed #ccc; border-radius: 8px; padding: 15px; text-align: center; margin-bottom: 15px; transition: 0.2s; background: #fafafa; }
        .upload-box:hover { border-color: #0066cc; background: #f0f7ff; }
        .upload-box.loaded { border-color: #28a745; background: #e8f5e9; }
        .upload-box p { margin: 5px 0; font-weight: bold; font-size: 0.9rem; }
        input[type="file"] { font-size: 0.8rem; }

        /* Model List */
        #model-list { list-style: none; padding: 0; margin: 0; text-align: left; }
        #model-list li { background: #fff; border: 1px solid #ddd; padding: 8px; margin-top: 5px; border-radius: 4px; font-size: 0.85rem; display: flex; justify-content: space-between; align-items: center; }
        #model-list li span.tag { background: #e3f2fd; color: #0d47a1; padding: 2px 6px; border-radius: 4px; font-size: 0.75rem; font-weight: bold; margin-right: 8px; }

        /* Visualization Area */
        #wsi-wrapper { 
            position: relative; 
            width: 100%; 
            height: 300px; 
            background: #ffffff; 
            border: 1px solid #e0e0e0; 
            border-radius: 8px; 
            overflow: hidden; 
            display: flex; 
            align-items: center; 
            justify-content: center; 
        }
        #wsi-vis { max-width: 100%; max-height: 100%; object-fit: contain; }
        
        /* Progress */
        .status-bar { margin-top: 20px; }
        .progress-track { height: 12px; background: #e0e0e0; border-radius: 6px; overflow: hidden; margin-bottom: 5px; }
        .progress-fill { height: 100%; width: 0%; background: #0066cc; transition: width 0.2s; }
        .status-text { font-size: 0.9rem; color: #555; font-weight: 600; display: flex; justify-content: space-between; }

        /* Results Table */
        .results-table { width: 100%; border-collapse: collapse; margin-top: 15px; font-size: 0.9rem; }
        .results-table th { text-align: left; border-bottom: 2px solid #eee; padding: 8px; color: #666; }
        .results-table td { border-bottom: 1px solid #f0f0f0; padding: 8px; vertical-align: middle; }
        .badge { padding: 4px 8px; border-radius: 12px; font-weight: bold; font-size: 0.8rem; }
        .badge.pos { background: #ffebee; color: #c62828; }
        .badge.neg { background: #e8f5e9; color: #2e7d32; }

        /* Controls */
        .controls-area { margin-top: auto; }
        .viz-toggle { display: block; margin-bottom: 15px; padding: 10px; background: #f8f9fa; border-radius: 6px; font-size: 0.9rem; cursor: pointer; border: 1px solid #eee; }
        .viz-toggle input { margin-right: 10px; }

        #btn-run { background: #0066cc; color: white; border: none; padding: 15px; font-size: 1rem; font-weight: bold; border-radius: 8px; cursor: pointer; width: 100%; transition: 0.2s; }
        #btn-run:disabled { background: #ccc; cursor: not-allowed; }
        #btn-run:hover:not(:disabled) { background: #0052a3; }

        /* Console Log */
        #console { background: #222; color: #0f0; font-family: monospace; padding: 15px; border-radius: 8px; height: 120px; overflow-y: auto; font-size: 12px; margin-top: 20px; border: 1px solid #444; }
        .log-line { margin-bottom: 4px; }
        .log-err { color: #ff5555; }
    </style>
</head>
<body>

    <div id="global-error"></div>

    <h1>ðŸ§¬ Client-Side WSI Pipeline (Multi-Task)</h1>
    <p class="subtitle">Simultaneous inference of multiple biomarkers from a single slide.</p>

    <div class="grid-container">
        <!-- LEFT: SETUP -->
        <div class="card">
            <h3>1. Load Models</h3>
            
            <!-- Backbone -->
            <div class="upload-box" id="box-backbone">
                <p>Feature Extractor (Backbone)</p>
                <small>Upload <code>mobileone.onnx</code></small>
                <input type="file" id="file-backbone" accept=".onnx">
            </div>

            <!-- Classifiers List -->
            <div class="upload-box" id="box-classifiers">
                <p>Downstream Classifiers (STAMP)</p>
                <small>Select multiple .onnx files (e.g., BRAF, MSI)</small>
                <input type="file" id="file-classifiers" accept=".onnx" multiple>
                <ul id="model-list"></ul>
            </div>

            <h3>2. Load Slide</h3>
            <div class="upload-box" id="box-slide">
                <p>Whole Slide Image (.tif)</p>
                <input type="file" id="file-slide" accept=".tif,.tiff">
            </div>
            
            <div id="level-container" style="display:none; margin-bottom: 15px;">
                <select id="level-select" style="width:100%; padding:8px;"></select>
            </div>

            <div class="controls-area">
                <label class="viz-toggle">
                    <input type="checkbox" id="cb-viz" checked> 
                    Show Visualization
                </label>
                <button id="btn-run" disabled>ðŸš€ Run Pipeline</button>
            </div>
        </div>

        <!-- RIGHT: RESULTS -->
        <div class="card">
            <h3>3. Analysis & Results</h3>
            <div id="wsi-wrapper">
                <canvas id="wsi-vis"></canvas>
            </div>

            <div class="status-bar">
                <div class="progress-track"><div id="p-bar" class="progress-fill"></div></div>
                <div class="status-text">
                    <span id="p-status">Waiting...</span>
                    <span id="p-percent">0%</span>
                </div>
            </div>

            <!-- Results Table -->
            <table class="results-table" id="results-table">
                <thead>
                    <tr>
                        <th>Biomarker Task</th>
                        <th>Prediction</th>
                        <th>Confidence</th>
                    </tr>
                </thead>
                <tbody id="results-body">
                    <tr><td colspan="3" style="text-align:center; color:#999;">No results yet</td></tr>
                </tbody>
            </table>
        </div>
    </div>

    <div id="console">
        <div class="log-line">System Initialized. Load your models.</div>
    </div>

    <!-- Hidden Canvas -->
    <canvas id="proc-canvas" width="224" height="224" style="display:none;"></canvas>

    <script>
        window.onerror = function(message, source, lineno, colno, error) {
            document.getElementById('global-error').style.display = 'block';
            document.getElementById('global-error').innerText = `ERROR: ${message} at line ${lineno}`;
        };

        // --- CONFIG ---
        const TILE_SIZE = 224;
        const MAX_PREVIEW_PIXELS = 10000000;

        // --- STATE ---
        let backboneSess = null;
        let classifiers = []; // Array of { name: string, session: ort.InferenceSession }
        let tiff = null;
        let tiffImage = null;

        // --- UTILS ---
        const log = (msg, err=false) => {
            const c = document.getElementById('console');
            if(!c) return;
            c.innerHTML += `<div class="log-line ${err?'log-err':''} ">> ${msg}</div>`;
            c.scrollTop = c.scrollHeight;
        };

        // --- COLOR CORRECTION ---
        function ycbcrToRgb(y, cb, cr) {
            const c = y - 16;
            const d = cb - 128;
            const e = cr - 128;
            return [
                Math.max(0, Math.min(255, (1.164 * c + 1.596 * e))),
                Math.max(0, Math.min(255, (1.164 * c - 0.391 * d - 0.813 * e))),
                Math.max(0, Math.min(255, (1.164 * c + 2.018 * d)))
            ];
        }

        function convertToRGBA(rasters, width, height, fileDirectory) {
            const total = width * height;
            const rgba = new Uint8ClampedArray(total * 4);
            const isYCbCr = fileDirectory.PhotometricInterpretation === 6;

            if (isYCbCr && rasters.length === total * 3) {
                for (let i=0, j=0; i<rasters.length; i+=3, j+=4) {
                    const [r, g, b] = ycbcrToRgb(rasters[i], rasters[i+1], rasters[i+2]);
                    rgba[j]=r; rgba[j+1]=g; rgba[j+2]=b; rgba[j+3]=255;
                }
                return rgba;
            }
            if (rasters.length === total * 3) {
                for (let i=0, j=0; i<rasters.length; i+=3, j+=4) {
                    rgba[j]=rasters[i]; rgba[j+1]=rasters[i+1]; rgba[j+2]=rasters[i+2]; rgba[j+3]=255;
                }
                return rgba;
            }
            if (rasters.length === total * 4) return new Uint8ClampedArray(rasters);
            throw new Error("Unsupported channel count");
        }

        // --- MODEL LOADING ---
        async function loadBackbone(file) {
            try {
                const buffer = await file.arrayBuffer();
                backboneSess = await ort.InferenceSession.create(buffer, { executionProviders: ['wasm'] });
                document.getElementById('box-backbone').classList.add('loaded');
                log("Backbone loaded.");
                checkReady();
            } catch(e) { log(`Backbone Error: ${e.message}`, true); }
        }

        async function loadClassifiers(files) {
            const list = document.getElementById('model-list');
            list.innerHTML = "";
            classifiers = [];

            for (const file of files) {
                try {
                    const buffer = await file.arrayBuffer();
                    const sess = await ort.InferenceSession.create(buffer, { executionProviders: ['wasm'] });
                    
                    // Use filename as Task Name (e.g., "BRAF.onnx" -> "BRAF")
                    const name = file.name.replace(/\.[^/.]+$/, "").replace(/_/g, " ");
                    classifiers.push({ name: name, session: sess });

                    // UI
                    const li = document.createElement('li');
                    li.innerHTML = `<span><span class="tag">TASK</span>${name}</span> <span>âœ… Ready</span>`;
                    list.appendChild(li);
                } catch(e) {
                    log(`Error loading ${file.name}`, true);
                }
            }
            if(classifiers.length > 0) {
                document.getElementById('box-classifiers').classList.add('loaded');
                log(`${classifiers.length} classifiers loaded.`);
            }
            checkReady();
        }

        document.getElementById('file-backbone').onchange = e => loadBackbone(e.target.files[0]);
        document.getElementById('file-classifiers').onchange = e => loadClassifiers(e.target.files);

        // --- SLIDE LOADING ---
        document.getElementById('file-slide').onchange = async (e) => {
            try {
                tiff = await GeoTIFF.fromBlob(e.target.files[0]);
                
                // Level Setup
                const count = await tiff.getImageCount();
                const select = document.getElementById('level-select');
                select.innerHTML = "";
                for(let i=0; i<count; i++) {
                    const img = await tiff.getImage(i);
                    const opt = document.createElement("option");
                    opt.value = i;
                    opt.text = `Level ${i} (${img.getWidth()}x${img.getHeight()})`;
                    select.appendChild(opt);
                }
                document.getElementById('level-container').style.display = 'block';
                select.value = "0"; // Default to highest res
                await loadLevel(0);

                document.getElementById('box-slide').classList.add('loaded');
                checkReady();
            } catch(e) { log(`Slide Error: ${e.message}`, true); }
        };

        document.getElementById('level-select').onchange = e => loadLevel(parseInt(e.target.value));

        async function loadLevel(index) {
            tiffImage = await tiff.getImage(index);
            const w = tiffImage.getWidth();
            const h = tiffImage.getHeight();
            log(`Selected Level ${index}: ${w}x${h} px`);
            
            initVisualizer(w, h);
            if (w*h < MAX_PREVIEW_PIXELS) await generateOverview(tiffImage);
            else await tryGeneratePyramidOverview(tiff);
        }

        function initVisualizer(w, h) {
            const c = document.getElementById('wsi-vis');
            const wrap = document.getElementById('wsi-wrapper');
            const scale = Math.min(wrap.clientWidth/w, wrap.clientHeight/h);
            c.width = w * scale;
            c.height = h * scale;
            const ctx = c.getContext('2d');
            ctx.fillStyle = "#ffffff";
            ctx.fillRect(0, 0, c.width, c.height);
            ctx.fillStyle = "#999";
            ctx.textAlign = "center";
            ctx.fillText("Loading Map...", c.width/2, c.height/2);
        }

        async function generateOverview(img) {
            await renderToCanvas(img);
        }

        async function tryGeneratePyramidOverview(handler) {
            const count = await handler.getImageCount();
            for(let i=1; i<count; i++) {
                const sub = await handler.getImage(i);
                if(sub.getWidth()*sub.getHeight() < MAX_PREVIEW_PIXELS) {
                    await renderToCanvas(sub);
                    return;
                }
            }
            // Clear canvas if no preview
            const c = document.getElementById('wsi-vis');
            c.getContext('2d').fillStyle="#fff";
            c.getContext('2d').fillRect(0,0,c.width,c.height);
        }

        async function renderToCanvas(source) {
            try {
                const w = source.getWidth();
                const h = source.getHeight();
                const rasters = await source.readRasters({interleave:true});
                const rgba = convertToRGBA(rasters, w, h, source.fileDirectory);
                const imgData = new ImageData(rgba, w, h);
                const bmp = await createImageBitmap(imgData);
                const c = document.getElementById('wsi-vis');
                c.getContext('2d').drawImage(bmp, 0, 0, c.width, c.height);
            } catch(e) { console.warn("Preview generation failed"); }
        }

        function checkReady() {
            if(backboneSess && classifiers.length > 0 && tiffImage) {
                document.getElementById('btn-run').disabled = false;
            }
        }

        // --- PROCESSING HELPERS ---
        function isTissueRaw(rgba) {
            let tissue = 0;
            for(let i=0; i<rgba.length; i+=64) {
                if(rgba[i]<220 || rgba[i+1]<220 || rgba[i+2]<220) tissue++;
            }
            return tissue > ((rgba.length/4)/16)*0.05;
        }

        function toTensorRaw(rgba) {
            const f32 = new Float32Array(3 * TILE_SIZE * TILE_SIZE);
            const mean = [0.485, 0.456, 0.406];
            const std = [0.229, 0.224, 0.225];
            let p = 0;
            for(let i=0; i<rgba.length; i+=4) {
                f32[p] = (rgba[i]/255 - mean[0])/std[0];
                f32[p + TILE_SIZE**2] = (rgba[i+1]/255 - mean[1])/std[1];
                f32[p + 2*TILE_SIZE**2] = (rgba[i+2]/255 - mean[2])/std[2];
                p++;
            }
            return new ort.Tensor('float32', f32, [1, 3, TILE_SIZE, TILE_SIZE]);
        }

        // --- EXECUTION ---
        document.getElementById('btn-run').onclick = async () => {
            const btn = document.getElementById('btn-run');
            const doViz = document.getElementById('cb-viz').checked;
            btn.disabled = true; 
            btn.innerText = "Extracting Features...";
            
            document.getElementById('results-body').innerHTML = '<tr><td colspan="3" style="text-align:center;">Processing...</td></tr>';

            let features = [];
            const w = tiffImage.getWidth();
            const h = tiffImage.getHeight();
            const c = document.getElementById('wsi-vis');
            const ctx = c.getContext('2d');
            const scaleX = c.width / w;
            const scaleY = c.height / h;
            
            const xTiles = Math.ceil(w/TILE_SIZE);
            const yTiles = Math.ceil(h/TILE_SIZE);
            const total = xTiles * yTiles;
            
            log(`Starting run: ${total} tiles.`);
            let processed = 0;
            let accepted = 0;
            
            for (let y=0; y<h; y+=TILE_SIZE) {
                for (let x=0; x<w; x+=TILE_SIZE) {
                    const rW = Math.min(TILE_SIZE, w-x);
                    const rH = Math.min(TILE_SIZE, h-y);
                    
                    try {
                        const rasters = await tiffImage.readRasters({window:[x,y,x+rW,y+rH], interleave:true});
                        const rgba = convertToRGBA(rasters, rW, rH, tiffImage.fileDirectory);
                        
                        if(isTissueRaw(rgba)) {
                            if(doViz) {
                                ctx.fillStyle="rgba(0,255,0,0.4)";
                                ctx.fillRect(x*scaleX, y*scaleY, rW*scaleX, rH*scaleY);
                            }
                            
                            const feeds = {};
                            feeds[backboneSess.inputNames[0]] = toTensorRaw(rgba);
                            const res = await backboneSess.run(feeds);
                            features.push(Array.from(res[backboneSess.outputNames[0]].data));
                            accepted++;
                        } else {
                            if(doViz) {
                                ctx.fillStyle="rgba(200,200,200,0.2)";
                                ctx.fillRect(x*scaleX, y*scaleY, rW*scaleX, rH*scaleY);
                            }
                        }
                    } catch(e){}
                    
                    processed++;
                    if(processed%50===0 || processed===total) {
                        const pct = Math.round((processed/total)*100);
                        document.getElementById('p-bar').style.width = `${pct}%`;
                        document.getElementById('p-percent').innerText = `${pct}%`;
                        document.getElementById('p-status').innerText = `Scanning ${processed}/${total}`;
                        await new Promise(r=>setTimeout(r,0));
                    }
                }
            }
            
            log(`Extraction complete. ${accepted} tiles.`);
            
            if(features.length === 0) {
                log("No tissue found!", true);
                btn.disabled = false; btn.innerText = "Run Pipeline"; return;
            }

            // --- MULTI-TASK INFERENCE ---
            btn.innerText = "Running Classifiers...";
            const flatFeats = new Float32Array(features.flat());
            // [1, N, 512]
            const bagTensor = new ort.Tensor('float32', flatFeats, [1, features.length, 512]);
            
            const tbody = document.getElementById('results-body');
            tbody.innerHTML = ""; // Clear

            for (const clf of classifiers) {
                try {
                    const feeds = {};
                    feeds[clf.session.inputNames[0]] = bagTensor;
                    const res = await clf.session.run(feeds);
                    const logits = res[clf.session.outputNames[0]].data;
                    
                    // Softmax
                    const exps = logits.map(Math.exp);
                    const sum = exps.reduce((a,b)=>a+b);
                    const prob = exps[1]/sum; // Pos prob
                    const isPos = prob > 0.5;
                    
                    const row = document.createElement('tr');
                    row.innerHTML = `
                        <td><strong>${clf.name}</strong></td>
                        <td><span class="badge ${isPos ? 'pos' : 'neg'}">${isPos ? 'POSITIVE (+)' : 'NEGATIVE (-)'}</span></td>
                        <td>
                            <div style="background:#eee; height:6px; width:100px; border-radius:3px; overflow:hidden; display:inline-block; vertical-align:middle; margin-right:5px;">
                                <div style="background:${isPos?'#c62828':'#2e7d32'}; height:100%; width:${prob*100}%"></div>
                            </div>
                            ${(prob*100).toFixed(1)}%
                        </td>
                    `;
                    tbody.appendChild(row);
                    
                } catch(e) {
                    log(`Error running ${clf.name}: ${e.message}`, true);
                }
            }
            
            btn.disabled = false;
            btn.innerText = "Run Again";
        };
    </script>

</body>
</html>